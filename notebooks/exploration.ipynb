{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(path, target_size=(128, 128)):\n",
    "    # 1. Reading image\n",
    "    img = cv2.imread(str(path))\n",
    "    # 2. Change color system to gray\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 3. Resize\n",
    "    img = cv2.resize(img, target_size, interpolation=cv2.INTER_AREA)\n",
    "    # 4. Normalize\n",
    "    img = img.astype('float32') / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path('../data/raw/lfw_funneled/')\n",
    "data_path = list(data_root.rglob('*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_path: list[Path]):\n",
    "    train_path, temp_path = train_test_split(\n",
    "        data_path, train_size=0.8, test_size=0.2, random_state=42\n",
    "    )\n",
    "    val_path, test_path = train_test_split(\n",
    "        temp_path, train_size=0.1, test_size=0.1, random_state=42\n",
    "    )\n",
    "\n",
    "    return train_path, val_path, test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, val_paths, test_paths = split_data(data_path)\n",
    "print(len(data_path))\n",
    "print(type(train_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_list(image_paths: list[Path], target_size = (128, 128)):\n",
    "    X = []\n",
    "    Y = [] \n",
    "    unique_labels = sorted(list(set(p.parent.name for p in image_paths)))\n",
    "    label_to_idx = {name: i for i, name in enumerate(unique_labels)}\n",
    "    \n",
    "    print(f\"Đang xử lý {len(image_paths)} ảnh từ {len(unique_labels)} lớp...\")\n",
    "\n",
    "    # Loop for reading and preprocessing images\n",
    "    for p in tqdm(image_paths, desc=\"Đang xử lý ảnh\", unit=\"Ảnh\"):\n",
    "\n",
    "        try:\n",
    "            \n",
    "            img = preprocess_image(str(p), target_size)\n",
    "\n",
    "            # Add dim for image (128, 128) -> (128, 128, 1)\n",
    "            img = img.reshape(target_size[0], target_size[1], 1)\n",
    "            \n",
    "            X.append(img)\n",
    "            Y.append(label_to_idx[p.parent.name])\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi tại ảnh {p}: {e}\")\n",
    "    return np.array(X), np.array(Y), label_to_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_data_list(image_path)\n",
    "x_train, y_train, mapping = prepare_data_list(train_paths)\n",
    "x_val, y_val, _ = prepare_data_list(val_paths)\n",
    "x_test, y_test, _ = prepare_data_list(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = Path('../data/processed/')\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_split_data(name, save_dir, x, y, mapping=None):\n",
    "    file_path = save_dir / f'{name}.npz'\n",
    "\n",
    "    data_to_save = {'X': x, 'Y': y}\n",
    "    if mapping is not None:\n",
    "        data_to_save['mapping'] = mapping\n",
    "\n",
    "    np.savez_compressed(file_path, **data_to_save)\n",
    "\n",
    "save_split_data(\"train\", save_dir, x_train, y_train, mapping)\n",
    "save_split_data(\"test\", save_dir, x_test, y_test)\n",
    "save_split_data(\"val\", save_dir, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_load = np.load('../data/processed/test.npz', allow_pickle=True)\n",
    "print(test_load.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('../data/processed/train.npz', allow_pickle=True) as data:\n",
    "    x_train = data['X']\n",
    "    y_train = data['Y']\n",
    "    mapping = data['mapping'].item()\n",
    "with np.load('../data/processed/test.npz', allow_pickle=True) as data:\n",
    "    x_test = data['X']\n",
    "    y_test = data['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "def train_svm_with_pca(X_train, Y_train, X_test, Y_test, n_components=150):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 1. Flatting image\n",
    "    X_train_flat = X_train.reshape(len(X_train), -1)\n",
    "    X_test_flat = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "    # 2. PCA on train\n",
    "    pca = PCA(n_components=n_components, whiten=True, random_state=42)\n",
    "    pca.fit(X_train_flat)\n",
    "\n",
    "    # 3. Transform\n",
    "    X_train_pca = pca.transform(X_train_flat)\n",
    "    X_test_pca = pca.transform(X_test_flat)\n",
    "\n",
    "    # 4. Training svm\n",
    "    model = SVC(kernel='linear', C=1.0, gamma='scale', class_weight='balanced')\n",
    "    model.fit(X_train_pca, Y_train)\n",
    "\n",
    "    # 5. Evaluate\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"Training time: {end_time - start_time:.2f} second\")\n",
    "    # Predict for y hat\n",
    "    y_train_pred = model.predict(X_train_pca)\n",
    "    y_test_pred = model.predict(X_test_pca)\n",
    "\n",
    "    train_acc = accuracy_score(Y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(Y_test, y_test_pred)\n",
    "\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return model, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, pca = train_svm_with_pca(x_train, y_train, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
